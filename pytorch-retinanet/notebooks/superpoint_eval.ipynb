{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "\n",
    "from retinanet import model\n",
    "from retinanet.dataloader import CocoDataset, CSVDataset, collater, Resizer, AspectRatioBasedSampler, Augmenter, \\\n",
    "\tUnNormalizer, Normalizer\n",
    "from retinanet import csv_eval\n",
    "from retinanet.losses import *\n",
    "# Inmport superpoint\n",
    "from retinanet.networks.superpoint_pytorch import SuperPointFrontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_annotations_path = '/home/baudoin/pytorch-retinanet-pipeline/visdrone_anno/annotations_dev.csv'\n",
    "class_list_path = '/home/baudoin/pytorch-retinanet-pipeline/visdrone_anno/class_labels.csv'\n",
    "model_path = '/home/baudoin/pytorch-retinanet-pipeline/results/training_results/20220113-191006/checkpoints/checkpoint_csv_retinanet_16.pt'\n",
    "iou_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Load SuperPoint Pth from  checkpoints/superpoint/superpoint_v1.pth\n"
     ]
    }
   ],
   "source": [
    "dataset_val = CSVDataset(csv_annotations_path,class_list_path,transform=transforms.Compose([Normalizer(), Resizer()]))\n",
    "\n",
    "superpoint = SuperPointFrontend(project_root='') #Modify project_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_to_img(layer):\n",
    "    layer = layer.squeeze()[1:].unsqueeze(0)\n",
    "    pixel_shuffle = torch.nn.PixelShuffle(8)\n",
    "    output = pixel_shuffle(layer)\n",
    "    print('img shape')\n",
    "    print(output.size())\n",
    "\n",
    "    return output.squeeze()\n",
    "\n",
    "def draw_keypoints(img, corners, color):\n",
    "    keypoints = [cv2.KeyPoint(c[1], c[0], 1) for c in np.stack(corners).T]\n",
    "    return cv2.drawKeypoints(img.astype(np.uint8), keypoints, None, color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4199/2568142114.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdataset_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0miou_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscore_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmax_detections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_val' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = dataset_val\n",
    "del dataset_val\n",
    "iou_threshold=0.5\n",
    "score_threshold=0.05\n",
    "max_detections=100\n",
    "save_path=None\n",
    "\n",
    "for index in range(len(dataset)):\n",
    "    data = dataset[index]\n",
    "    print(data.keys())\n",
    "    scale = data['scale']\n",
    "\n",
    "    \n",
    "\n",
    "    # SuperPoint label with teacher model\n",
    "    output_superpoint = superpoint.run(data['img_gray'].permute(2, 0, 1).cuda().float().unsqueeze(dim=0))\n",
    "    desc_teacher = torch.from_numpy(output_superpoint['local_descriptor_map']).type(torch.FloatTensor)#.to(device)\n",
    "    dect_teacher = torch.from_numpy(output_superpoint['dense_scores']).type(torch.FloatTensor)#.to(device)\n",
    "    \n",
    "    img_original = data['img_gray'].numpy()*255\n",
    "    keypoints = layer_to_img(F.softmax(dect_teacher, dim=1))\n",
    "    corners = np.array(np.where(keypoints > 0.9)).astype('float')\n",
    "    img = draw_keypoints(img_original, corners, (0,255,0))\n",
    "    \n",
    "    plt.figure(figsize=(18,16))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(18,16))\n",
    "    plt.imshow(img_original)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "            \n",
    "            print(np.shape((np.array(output_superpoint['local_descriptor_map']))))\n",
    "            print(np.shape((np.array(output_superpoint['dense_scores']))))\n",
    "            import matplotlib.pyplot as plt\n",
    "            import cv2\n",
    "            def draw_keypoints(img, corners, color):\n",
    "                keypoints = [cv2.KeyPoint(c[1], c[0], 1) for c in np.stack(corners).T]\n",
    "                return cv2.drawKeypoints(img.astype(np.uint8), keypoints, None, color=color)\n",
    "            def plot(img, fig = 0):\n",
    "                plt.figure(fig)\n",
    "                plt.imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "                plt.show()  # display it\n",
    "                plt.savefig('/home/baudoin/pytorch-retinanet-pipeline/img1.png')\n",
    "            def layer_to_img(layer):\n",
    "                layer = layer.squeeze()[1:].unsqueeze(0)\n",
    "                pixel_shuffle = torch.nn.PixelShuffle(8)\n",
    "                output = pixel_shuffle(layer)\n",
    "                print('img shape')\n",
    "                print(output.size())\n",
    "\n",
    "                return output.squeeze()\n",
    "            keypoints = layer_to_img(F.softmax(output_semi, dim=1))\n",
    "            \n",
    "            print(data['img_gray'])\n",
    "\n",
    "            frame = draw_keypoints(data['img_gray'], np.where(keypoints > 0.5), (0,255,0))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c5ce1f4c9a1ce0bf8c0fe0c5b01ea903ea06a1ce01686680a10fac51ad47f3f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('pytorch-retinanet-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
